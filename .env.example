# === API Keys (local dev can rely on Ollama instead) ===
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=anthropic-...

# Use local Ollama on Mac for GPU via Metal:
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.1
# Embeddings (choose 'openai' or 'ollama')
EMBEDDINGS_PROVIDER=ollama
EMBEDDINGS_MODEL=text-embedding-3-small

# === Frontend ===
NEXT_PUBLIC_API_URL=http://backend:8000

# === Vector DB (Qdrant) ===
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=docs

# === Postgres ===
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=aistarter
POSTGRES_USER=aistarter
POSTGRES_PASSWORD=aistarter

# === Backend ===
API_HOST=0.0.0.0
API_PORT=8000
ENV=dev
